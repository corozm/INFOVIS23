{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of Dataset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "data = pd.read_csv('animal_sorted.csv')\n",
    "penguins = pd.unique(data['common_name'])\n",
    "sites = pd.unique(data['site_id'])\n",
    "years = list(range(2002, 2021))\n",
    "\n",
    "interpolated_data = []\n",
    "for penguin in penguins:\n",
    "    for site in sites:\n",
    "        filtered = data[(data['common_name'] == penguin) & (data['site_id'] == site)]\n",
    "        count = filtered.groupby('year')['penguin_count'].mean()\n",
    "        df = pd.DataFrame(index=years)\n",
    "        df['penguin_count'] = count\n",
    "        df = df.interpolate(method='linear', limit_direction='both').fillna(0.0)\n",
    "        df['common_name'] = penguin\n",
    "        df['site_id'] = site\n",
    "        interpolated_data.append(df.reset_index(names='year'))\n",
    "interpolated_data = pd.concat(interpolated_data, ignore_index='year')\n",
    "print(penguins)\n",
    "print(sites)\n",
    "print(years)\n",
    "print(interpolated_data)\n",
    "interpolated_data.to_csv('interpolated_penguin_data.csv', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of Dataset 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "combined_data = None\n",
    "\n",
    "for file_number in range(1, 19):\n",
    "    file_name = f'all{file_number}.xlsx'\n",
    "    data = pd.read_excel(file_name)\n",
    "    combined_data = pd.concat([combined_data, data], ignore_index=True)\n",
    "\n",
    "combined_data.to_csv('combined_data.csv', index=False)\n",
    "\n",
    "df = pd.read_csv('combined_data.csv')\n",
    "\n",
    "df = df.drop(columns='Days with average temperature ≥ 18 ℃')\n",
    "df = df.drop(columns='Days with average temperature ≥ 35 ℃')\n",
    "\n",
    "df.to_csv('antarctica_temperature.csv', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of Dataset 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "combined_data = None\n",
    "\n",
    "for file_number in range(1, 112):\n",
    "    file_name = f'{file_number}.csv'\n",
    "    data = pd.read_csv(file_name)\n",
    "    combined_data = pd.concat([combined_data, data], ignore_index=True)\n",
    "\n",
    "combined_data.to_csv('combined_data.csv', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of Dataset 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "df = pd.read_csv('sealevel.csv')\n",
    "df_yearly_max = df.groupby('year')['GMSL_GIA'].max().reset_index()\n",
    "\n",
    "df_yearly_max.to_csv('sealevel_year.csv', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}